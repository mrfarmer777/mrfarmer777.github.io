---
layout: post
title: "So...what is a Data Coach?"
sub-title: "The person you didn't know your school needed."
header-img: ""
tags: [education, edtech, data coaching, teaching]
---


I have served my current school district as an Instructional Data Coach for the past two school years. Recently, I was lucky enough to chat with a director of instructional technology from a large, elite university. She started our conversation with the following question: "So, what is a 'Data Coach'?" I had the thought that if someone of her background and experience doesn't know, perhaps a more thorough explanation might be in order of this emerging role. 

### The Instructional Data Coach 

> An educator and/or instructional designer who helps other educators improve instructional outcomes by collecting, aggregating, analyzing and visualizing student data. 

The above definition provides us a jumping-off point to understand this role and perhaps sounds a lot like a traditional [instructional coach](https://www.instructionalcoaching.com/what-do-instructional-coaches-do/) if you're familiar. In fact, this role was created at my district after a conversation with administrators about the instructional [coaching cycle](https://dianesweeney.com/measuring-the-impact-of-coaching-cycles/). 

I contend that the coaching cycle as an offshoot of the [ADDIE](https://www.instructionaldesign.org/models/addie/) model for instructional design. It's pretty simple at its heart: identify a problem, design a solution (using quick iterations), implement the solution, measure to see if the desired result was achieved. This is an effective strategy and is held up by considerable educational research. Awesome. But consider the following questions before you start a cycle: 

1. How do you know there's a "problem"?
2. How do you know when it's "solved"?

I feel that these questions can best be answered with data. So before engage in the 6 to 9 week coaching cycle, discuss research, and iterate solutions, and implement and assess those solutions we need to answer the questions above. What _data_ shows us there's a problem? What _data_ will tell us when it is solved? 
> But shouldn't all coaching cycles be centered around data anyway? What's the difference?

Maybe you're right; maybe data coaching is no different. Maybe I'm, say, a data-flavored instructional coach. That is totally fine. Given the emergent nature of instructional coaching in general, this is all very much in a state of flux. As you consider this distinction, I ask you to check out some of the lessons I've learned from my time in this role. Maybe data isn't as "integrated" and understood as it needs to be, or as we like to think it is. 

### The Warm and the Cold
If you've been in education for more than 1 day, you know that education is an extremely human endeavor. It's messy, it's emotional. It's draining, it's rewarding. It's important, it's difficult. Above all it's _complex_! This complexity often overwhelms many of us until we hear (perhaps subconsciously) the following statement:
> "At the end of the day, we all just want what is best for kids."  

Right. Doesn't that sound good? It gives you a fuzzy feeling. A feeling of _warmth_. And even after 14 years in the classroom, I still think it's true. The problem is, this feeling ignores the complexity I just mentioned. What does "best" mean? (That is a subject for an entire career of research, in my opinion.) How do you know when you're doing best for kids? The answer: you just _know_. When we give students another chance, we give them the tough-love, we prepare them for the harsh reality of what's next, or we use our own time/money to help them with their fundamental needs. We're doing right by them. We're giving them what's best. 

### Wild-West

### Conclusion
